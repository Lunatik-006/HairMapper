{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b444acd0",
      "metadata": {
        "id": "b444acd0",
        "outputId": "2a87c2be-cd42-4556-cd82-20e95598e576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a45fae3e99da>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Аутентификация в Google Drive (требуется в Colab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mgauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    261\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "# Ячейка 1: Setup и загрузка моделей\n",
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth  # Только для Colab\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Функция клонирования репозитория, если папка ещё не существует\n",
        "def clone_repo_if_not_exists(repo_url, dest_folder):\n",
        "    if os.path.exists(dest_folder):\n",
        "        print(f\"[INFO] Репозиторий уже существует: {dest_folder}\")\n",
        "        return\n",
        "    print(f\"[INFO] Клонирование репозитория: {repo_url}\")\n",
        "    subprocess.run(['git', 'clone', repo_url, dest_folder], check=True)\n",
        "    print(f\"[INFO] Репозиторий успешно клонирован в: {dest_folder}\")\n",
        "\n",
        "# Функция для скачивания файла с Google Drive, если он ещё не скачан\n",
        "def download_from_google_drive(file_id, file_dst):\n",
        "    if os.path.exists(file_dst):\n",
        "        print(f\"[INFO] Файл уже существует: {file_dst}\")\n",
        "        return\n",
        "    print(f\"[INFO] Скачивание файла в: {file_dst}\")\n",
        "    downloaded = drive.CreateFile({'id': file_id})\n",
        "    downloaded.FetchMetadata(fetch_all=True)\n",
        "    downloaded.GetContentFile(file_dst)\n",
        "    print(f\"[INFO] Файл успешно скачан: {file_dst}\")\n",
        "\n",
        "# Аутентификация в Google Drive (требуется в Colab)\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Клонируем репозиторий HairMapper, если он ещё не существует\n",
        "REPO_URL = \"https://github.com/Lunatik-006/HairMapper.git\"\n",
        "REPO_FOLDER = \"./HairMapper\"\n",
        "clone_repo_if_not_exists(REPO_URL, REPO_FOLDER)\n",
        "\n",
        "# Переходим в папку репозитория\n",
        "os.chdir(REPO_FOLDER)\n",
        "print(\"[INFO] Текущая рабочая директория:\", os.getcwd())\n",
        "\n",
        "# Загрузка чекпоинтов моделей\n",
        "checkpoints = {\n",
        "    'StyleGAN2-ada-Generator.pth': {'url': '1EsGehuEdY4z4t21o2LgW2dSsyN3rxYLJ', 'dir': './ckpts'},\n",
        "    'e4e_ffhq_encode.pt': {'url': '1cUv_reLE6k3604or78EranS7XzuVMWeO', 'dir': './ckpts'},\n",
        "    'model_ir_se50.pth': {'url': '1GIMopzrt2GE_4PG-_YxmVqTQEiaqu5L6', 'dir': './ckpts'},\n",
        "    'face_parsing.pth': {'url': '1IMsrkXA9NuCEy1ij8c8o6wCrAxkmjNPZ', 'dir': './ckpts'},\n",
        "    'vgg16.pth': {'url': '1EPhkEP_1O7ZVk66aBeKoFqf3xiM4BHH8', 'dir': './ckpts'}\n",
        "}\n",
        "for ckpt_name, info in checkpoints.items():\n",
        "    output_dir = info['dir']\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Создаем папку, если её нет\n",
        "    output_path = os.path.join(output_dir, ckpt_name)\n",
        "    download_from_google_drive(file_id=info['url'], file_dst=output_path)\n",
        "\n",
        "# Загрузка чекпоинтов классификаторов (gender/hair)\n",
        "classification_ckpt = [\n",
        "    {'url': '1SSw6vd-25OGnLAE0kuA-_VHabxlsdLXL', 'dir': './classifier/gender_classification'},\n",
        "    {'url': '1n14ckDcgiy7eu-e9XZhqQYb5025PjSpV', 'dir': './classifier/hair_classification'}\n",
        "]\n",
        "for clf in classification_ckpt:\n",
        "    output_dir = clf['dir']\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = os.path.join(output_dir, 'classification_model.pth')\n",
        "    download_from_google_drive(file_id=clf['url'], file_dst=output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86004b72",
      "metadata": {
        "id": "86004b72"
      },
      "outputs": [],
      "source": [
        "# Ячейка 2: Установка пакетов\n",
        "!pip install torch===2.0.0+cu117 torchvision===0.15.0+cu117 torchaudio===2.0.0+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -r requirements.txt\n",
        "!pip install pillow==9.5.0\n",
        "!pip install \"numpy<2.0\"\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3888df7b",
      "metadata": {
        "id": "3888df7b"
      },
      "outputs": [],
      "source": [
        "# Ячейка 3: Загрузка модели mapper и тестового изображения (для отладки)\n",
        "# Здесь загружается модель mapper в папку ./mapper/checkpoints/final\n",
        "mapper_url = 'https://drive.google.com/file/d/1F3oujXbvalqEOixcAkIyURuY512nmroe'\n",
        "mapper_id = mapper_url.replace('https://drive.google.com/file/d/', '').split('/')[0]\n",
        "mapper_output_dir = './mapper/checkpoints/final'\n",
        "os.makedirs(mapper_output_dir, exist_ok=True)\n",
        "mapper_output_path = os.path.join(mapper_output_dir, 'best_model.pt')\n",
        "download_from_google_drive(file_id=mapper_id, file_dst=mapper_output_path)\n",
        "\n",
        "# Тестовое изображение загружается в папку ./test_data/origin (для отладки)\n",
        "test_img_name = 'test_img.png'\n",
        "test_img_id = '1Ju5jLtNCALHJ2crJkMr00UP_ZUQzQBRs'\n",
        "test_img_dir = './test_data/origin'\n",
        "os.makedirs(test_img_dir, exist_ok=True)\n",
        "test_img_path = os.path.join(test_img_dir, test_img_name)\n",
        "download_from_google_drive(file_id=test_img_id, file_dst=test_img_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21a007c",
      "metadata": {
        "id": "c21a007c"
      },
      "outputs": [],
      "source": [
        "# Ячейка 4: Переход в папку encoder4editing и загрузка модели pSp (энкодер e4e)\n",
        "os.chdir('./encoder4editing')\n",
        "print(\"[INFO] Текущая директория (encoder4editing):\", os.getcwd())\n",
        "\n",
        "from argparse import Namespace\n",
        "import sys\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from PIL import ImageFile\n",
        "import glob\n",
        "import argparse\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from models.psp import pSp  # Импорт модели pSp\n",
        "\n",
        "# Трансформации для входного изображения (из папки с исходными изображениями)\n",
        "img_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "# Загрузка чекпоинта энкодера e4e из папки ./ckpts\n",
        "model_path = \"../ckpts/e4e_ffhq_encode.pt\"\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts = Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print(\"[INFO] Модель pSp (энкодер e4e) загружена.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d6d9a3",
      "metadata": {
        "id": "31d6d9a3"
      },
      "outputs": [],
      "source": [
        "# Ячейка 5: Обработка изображений из папки на Google Drive с входными данными\n",
        "# Этот блок считывает изображения из указанной входной папки на Google Drive,\n",
        "# обрабатывает их (удаление волос) и сохраняет результаты в локальную папку.\n",
        "# В конце результаты упаковываются в ZIP-архив и автоматически скачиваются на ПК.\n",
        "\n",
        "import zipfile\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Укажите ID входной папки на Google Drive с исходными изображениями\n",
        "# (напр., ссылка вида https://drive.google.com/drive/folders/XXX, где XXX - это ID)\n",
        "# aligned https://drive.google.com/drive/folders/15QuG_Iu8JAmVOJ-9HEJzBrk80NujHbqb?usp=drive_link\n",
        "# test https://drive.google.com/drive/folders/1O9ggebXzePLWBW2h4mo7ZZ13gGlF2Roa?usp=sharing\n",
        "input_folder_id = '1O9ggebXzePLWBW2h4mo7ZZ13gGlF2Roa'  # Замените на реальный ID входной папки\n",
        "\n",
        "# Локальные папки для временного хранения входных и выходных изображений\n",
        "temp_input_folder = './temp_input'\n",
        "os.makedirs(temp_input_folder, exist_ok=True)\n",
        "output_folder = './temp_output'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Получение списка файлов из входной папки по MIME-типу (png и jpg)\n",
        "query = f\"'{input_folder_id}' in parents and (mimeType='image/png')\"\n",
        "input_file_list = drive.ListFile({'q': query}).GetList()\n",
        "total_files = len(input_file_list)\n",
        "print(f\"[INFO] Найдено {total_files} входных изображений.\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "pbar = tqdm(total=total_files)\n",
        "for f in input_file_list:\n",
        "    pbar.update(1)\n",
        "    file_title = f['title']\n",
        "    # Скачиваем файл во временную папку\n",
        "    local_input_path = os.path.join(temp_input_folder, file_title)\n",
        "    f.GetContentFile(local_input_path)\n",
        "\n",
        "    # Открываем изображение с помощью PIL и применяем трансформации\n",
        "    try:\n",
        "        input_img = PIL.Image.open(local_input_path).convert('RGB')\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Не удалось открыть {file_title}: {e}\")\n",
        "        continue\n",
        "    transformed_image = img_transforms(input_img)\n",
        "\n",
        "    # Получаем латентное представление с помощью модели pSp\n",
        "    with torch.no_grad():\n",
        "        latents = net(transformed_image.unsqueeze(0).cuda().float(), randomize_noise=False, return_latents=True)\n",
        "        latent = latents[0].cpu().numpy()\n",
        "        latent = np.reshape(latent, (1, 18, 512))\n",
        "\n",
        "    # Применяем mapper для корректировки латентного кода (удаление волос)\n",
        "    mapper_input = latent.copy()\n",
        "    mapper_input_tensor = torch.from_numpy(mapper_input).cuda().float()\n",
        "    edited_latent_codes = latent\n",
        "    edited_latent_codes[:, :8, :] += alpha * mapper(mapper_input_tensor).to('cpu').detach().numpy()\n",
        "\n",
        "    # Генерация нового изображения с помощью генератора StyleGAN2-ada\n",
        "    outputs = model.easy_style_mixing(latent_codes=edited_latent_codes,\n",
        "                                      style_range=range(7,18),\n",
        "                                      style_codes=latent,\n",
        "                                      mix_ratio=0.8,\n",
        "                                      **kwargs)\n",
        "    edited_img = outputs['image'][0][:, :, ::-1]  # Преобразование из BGR в RGB\n",
        "\n",
        "    # Получаем исходное изображение для получения маски (считываем локально скачанный файл)\n",
        "    origin_img = cv2.imread(local_input_path)\n",
        "\n",
        "    # Извлекаем маску волос и применяем seamlessClone\n",
        "    hair_mask = get_hair_mask(img_path=origin_img, net=parsingNet, include_hat=True, include_ear=True)\n",
        "    mask_dilate = cv2.dilate(hair_mask, kernel=np.ones((50, 50), np.uint8))\n",
        "    mask_dilate_blur = cv2.blur(mask_dilate, ksize=(30,30))\n",
        "    mask_dilate_blur = (hair_mask + (255 - hair_mask)/255 * mask_dilate_blur).astype(np.uint8)\n",
        "    face_mask = 255 - mask_dilate_blur\n",
        "    face_mask = cv2.resize(face_mask, (origin_img.shape[1], origin_img.shape[0]))\n",
        "    idx = np.where(face_mask > 0)\n",
        "    cy = (np.min(idx[0]) + np.max(idx[0])) // 2\n",
        "    cx = (np.min(idx[1]) + np.max(idx[1])) // 2\n",
        "    center = (cx, cy)\n",
        "\n",
        "    # Применяем seamlessClone для объединения изображений\n",
        "    result_img = cv2.seamlessClone(origin_img, edited_img, face_mask[:, :, 0], center, cv2.NORMAL_CLONE)\n",
        "\n",
        "    # Сохраняем обработанное изображение в папку output_folder с расширением .png\n",
        "    output_filename = os.path.splitext(file_title)[0] + '.png'\n",
        "    local_output_path = os.path.join(output_folder, output_filename)\n",
        "    cv2.imwrite(local_output_path, result_img)\n",
        "pbar.close()\n",
        "\n",
        "print(\"[INFO] Обработка завершена. Обработанные изображения сохранены в:\", output_folder)\n",
        "\n",
        "# Создаем ZIP-архив из папки с обработанными изображениями\n",
        "zip_filename = \"processed_images.zip\"\n",
        "!zip -r {zip_filename} {output_folder}\n",
        "print(f\"[INFO] Архив {zip_filename} создан.\")\n",
        "\n",
        "# Автоматическое скачивание ZIP-архива на ПК\n",
        "files.download(zip_filename)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}