{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b444acd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b444acd0",
        "outputId": "52723bc4-2049-42ad-8374-19567e661455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Клонирование репозитория: https://github.com/Lunatik-006/HairMapper.git\n",
            "[INFO] Репозиторий успешно клонирован в: ./HairMapper\n",
            "[INFO] Текущая рабочая директория: /content/HairMapper\n",
            "[INFO] Скачивание файла в: ./ckpts/StyleGAN2-ada-Generator.pth\n",
            "[INFO] Файл успешно скачан: ./ckpts/StyleGAN2-ada-Generator.pth\n",
            "[INFO] Скачивание файла в: ./ckpts/e4e_ffhq_encode.pt\n",
            "[INFO] Файл успешно скачан: ./ckpts/e4e_ffhq_encode.pt\n",
            "[INFO] Скачивание файла в: ./ckpts/model_ir_se50.pth\n",
            "[INFO] Файл успешно скачан: ./ckpts/model_ir_se50.pth\n",
            "[INFO] Скачивание файла в: ./ckpts/face_parsing.pth\n",
            "[INFO] Файл успешно скачан: ./ckpts/face_parsing.pth\n",
            "[INFO] Скачивание файла в: ./ckpts/vgg16.pth\n",
            "[INFO] Файл успешно скачан: ./ckpts/vgg16.pth\n",
            "[INFO] Скачивание файла в: ./classifier/gender_classification/classification_model.pth\n",
            "[INFO] Файл успешно скачан: ./classifier/gender_classification/classification_model.pth\n",
            "[INFO] Скачивание файла в: ./classifier/hair_classification/classification_model.pth\n",
            "[INFO] Файл успешно скачан: ./classifier/hair_classification/classification_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Ячейка 1: Setup и загрузка моделей\n",
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth  # Только для Colab\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Функция клонирования репозитория, если папка ещё не существует\n",
        "def clone_repo_if_not_exists(repo_url, dest_folder):\n",
        "    if os.path.exists(dest_folder):\n",
        "        print(f\"[INFO] Репозиторий уже существует: {dest_folder}\")\n",
        "        return\n",
        "    print(f\"[INFO] Клонирование репозитория: {repo_url}\")\n",
        "    subprocess.run(['git', 'clone', repo_url, dest_folder], check=True)\n",
        "    print(f\"[INFO] Репозиторий успешно клонирован в: {dest_folder}\")\n",
        "\n",
        "# Функция для скачивания файла с Google Drive, если он ещё не скачан\n",
        "def download_from_google_drive(file_id, file_dst):\n",
        "    if os.path.exists(file_dst):\n",
        "        print(f\"[INFO] Файл уже существует: {file_dst}\")\n",
        "        return\n",
        "    print(f\"[INFO] Скачивание файла в: {file_dst}\")\n",
        "    downloaded = drive.CreateFile({'id': file_id})\n",
        "    downloaded.FetchMetadata(fetch_all=True)\n",
        "    downloaded.GetContentFile(file_dst)\n",
        "    print(f\"[INFO] Файл успешно скачан: {file_dst}\")\n",
        "\n",
        "# Аутентификация в Google Drive (требуется в Colab)\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Клонируем репозиторий HairMapper, если он ещё не существует\n",
        "REPO_URL = \"https://github.com/Lunatik-006/HairMapper.git\"\n",
        "REPO_FOLDER = \"./HairMapper\"\n",
        "clone_repo_if_not_exists(REPO_URL, REPO_FOLDER)\n",
        "\n",
        "# Переходим в папку репозитория\n",
        "os.chdir(REPO_FOLDER)\n",
        "print(\"[INFO] Текущая рабочая директория:\", os.getcwd())\n",
        "\n",
        "# Загрузка чекпоинтов моделей\n",
        "checkpoints = {\n",
        "    'StyleGAN2-ada-Generator.pth': {'url': '1EsGehuEdY4z4t21o2LgW2dSsyN3rxYLJ', 'dir': './ckpts'},\n",
        "    'e4e_ffhq_encode.pt': {'url': '1cUv_reLE6k3604or78EranS7XzuVMWeO', 'dir': './ckpts'},\n",
        "    'model_ir_se50.pth': {'url': '1GIMopzrt2GE_4PG-_YxmVqTQEiaqu5L6', 'dir': './ckpts'},\n",
        "    'face_parsing.pth': {'url': '1IMsrkXA9NuCEy1ij8c8o6wCrAxkmjNPZ', 'dir': './ckpts'},\n",
        "    'vgg16.pth': {'url': '1EPhkEP_1O7ZVk66aBeKoFqf3xiM4BHH8', 'dir': './ckpts'}\n",
        "}\n",
        "for ckpt_name, info in checkpoints.items():\n",
        "    output_dir = info['dir']\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Создаем папку, если её нет\n",
        "    output_path = os.path.join(output_dir, ckpt_name)\n",
        "    download_from_google_drive(file_id=info['url'], file_dst=output_path)\n",
        "\n",
        "# Загрузка чекпоинтов классификаторов (gender/hair)\n",
        "classification_ckpt = [\n",
        "    {'url': '1SSw6vd-25OGnLAE0kuA-_VHabxlsdLXL', 'dir': './classifier/gender_classification'},\n",
        "    {'url': '1n14ckDcgiy7eu-e9XZhqQYb5025PjSpV', 'dir': './classifier/hair_classification'}\n",
        "]\n",
        "for clf in classification_ckpt:\n",
        "    output_dir = clf['dir']\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = os.path.join(output_dir, 'classification_model.pth')\n",
        "    download_from_google_drive(file_id=clf['url'], file_dst=output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86004b72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86004b72",
        "outputId": "2aba1163-00ef-4851-c31f-3e0e07abb89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch===2.0.0+cu117 in /usr/local/lib/python3.11/dist-packages (2.0.0+cu117)\n",
            "Requirement already satisfied: torchvision===0.15.0+cu117 in /usr/local/lib/python3.11/dist-packages (0.15.0+cu117)\n",
            "Requirement already satisfied: torchaudio===2.0.0+cu117 in /usr/local/lib/python3.11/dist-packages (2.0.0+cu117)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision===0.15.0+cu117) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision===0.15.0+cu117) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision===0.15.0+cu117) (11.1.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch===2.0.0+cu117) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch===2.0.0+cu117) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch===2.0.0+cu117) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch===2.0.0+cu117) (1.3.0)\n",
            "Collecting tqdm==4.60.0 (from -r requirements.txt (line 1))\n",
            "  Using cached tqdm-4.60.0-py2.py3-none-any.whl.metadata (57 kB)\n",
            "Collecting requests==2.25.1 (from -r requirements.txt (line 2))\n",
            "  Using cached requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting matplotlib==3.4.1 (from -r requirements.txt (line 3))\n",
            "  Using cached matplotlib-3.4.1.tar.gz (37.3 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyYAML==5.4.1 (from -r requirements.txt (line 4))\n",
            "  Using cached PyYAML-5.4.1.tar.gz (175 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "--2025-04-07 23:01:54--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250407%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250407T230154Z&X-Amz-Expires=300&X-Amz-Signature=f29ee3141fd3611c14bc8e1b36faf03d75fc8c38d5cb65ebfb9971b4d63e5cb8&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-07 23:01:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250407%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250407T230154Z&X-Amz-Expires=300&X-Amz-Signature=f29ee3141fd3611c14bc8e1b36faf03d75fc8c38d5cb65ebfb9971b4d63e5cb8&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip.2’\n",
            "\n",
            "ninja-linux.zip.2   100%[===================>]  76.03K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-04-07 23:01:55 (763 KB/s) - ‘ninja-linux.zip.2’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "replace /usr/local/bin/ninja? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: /usr/local/bin/ninja    \n"
          ]
        }
      ],
      "source": [
        "# Ячейка 2: Установка пакетов\n",
        "!pip install torch===2.0.0+cu117 torchvision===0.15.0+cu117 torchaudio===2.0.0+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -r requirements.txt\n",
        "!pip install \"numpy<2.0\"\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "import sys\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from PIL import ImageFile\n",
        "import glob\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "# Здесь загружается модель mapper из папки ./mapper/checkpoints/final\n",
        "mapper_url = 'https://drive.google.com/file/d/1F3oujXbvalqEOixcAkIyURuY512nmroe'\n",
        "mapper_id = mapper_url.replace('https://drive.google.com/file/d/', '').split('/')[0]\n",
        "mapper_output_dir = './mapper/checkpoints/final'\n",
        "os.makedirs(mapper_output_dir, exist_ok=True)\n",
        "mapper_output_path = os.path.join(mapper_output_dir, 'best_model.pt')\n",
        "download_from_google_drive(file_id=mapper_id, file_dst=mapper_output_path)\n",
        "\n",
        "# Импорт необходимых классов для mapper и генератора\n",
        "# (Убедитесь, что пути импорта соответствуют структуре репозитория HairMapper)\n",
        "from mapper.networks.level_mapper import LevelMapper\n",
        "from styleGAN2_ada_model.stylegan2_ada_generator import StyleGAN2adaGenerator\n",
        "from classifier.src.feature_extractor.hair_mask_extractor import get_hair_mask, get_parsingNet\n",
        "\n",
        "# Инициализация генератора (StyleGAN2-ada)\n",
        "model_name = 'stylegan2_ada'\n",
        "print(\"[INFO] Инициализация генератора.\")\n",
        "model = StyleGAN2adaGenerator(model_name, logger=None, truncation_psi=1.0)\n",
        "\n",
        "# Инициализация mapper\n",
        "mapper = LevelMapper(input_dim=512).eval().cuda()\n",
        "mapper_ckpt = torch.load(mapper_output_path, map_location='cpu')\n",
        "alpha = float(mapper_ckpt['alpha']) * 1.2\n",
        "mapper.load_state_dict(mapper_ckpt['state_dict'], strict=True)\n",
        "\n",
        "# Параметры для генератора\n",
        "latent_space_type = 'wp'\n",
        "kwargs = {'latent_space_type': latent_space_type}\n",
        "\n",
        "# Загрузка парсинговой сети для извлечения маски волос /content/HairMapper/ckpts/face_parsing.pth\n",
        "parsingNet = get_parsingNet(save_pth='/content/HairMapper/ckpts/face_parsing.pth')\n",
        "\n",
        "# Тестовое изображение загружается в папку ./test_data/origin (для отладки)\n",
        "test_img_name = 'test_img.png'\n",
        "test_img_id = '1Ju5jLtNCALHJ2crJkMr00UP_ZUQzQBRs'\n",
        "test_img_dir = './test_data/origin'\n",
        "os.makedirs(test_img_dir, exist_ok=True)\n",
        "test_img_path = os.path.join(test_img_dir, test_img_name)\n",
        "download_from_google_drive(file_id=test_img_id, file_dst=test_img_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqGi4R7gpdno",
        "outputId": "b5b7796d-fe68-4473-939c-d760edfa49d7"
      },
      "id": "qqGi4R7gpdno",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:stylegan2_ada_generator:Load model from /content/HairMapper/ckpts/StyleGAN2-ada-Generator.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Файл уже существует: ./mapper/checkpoints/final/best_model.pt\n",
            "[INFO] Инициализация генератора.\n",
            "Loading pytorch model from `/content/HairMapper/ckpts/StyleGAN2-ada-Generator.pth`.\n",
            "load face_parsing model from:  /content/HairMapper/ckpts/face_parsing.pth\n",
            "[INFO] Скачивание файла в: ./test_data/origin/test_img.png\n",
            "[INFO] Файл успешно скачан: ./test_data/origin/test_img.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21a007c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c21a007c",
        "outputId": "f6c67fe5-dfb4-4e86-8ca0-86d18306c470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Текущая директория (encoder4editing): /content/HairMapper/encoder4editing\n",
            "Loading e4e over the pSp framework from checkpoint: ../ckpts/e4e_ffhq_encode.pt\n",
            "[INFO] Модель pSp (энкодер e4e) загружена.\n"
          ]
        }
      ],
      "source": [
        "# Ячейка 4: Переход в папку encoder4editing и загрузка модели pSp (энкодер e4e)\n",
        "os.chdir('/content/HairMapper/encoder4editing')\n",
        "print(\"[INFO] Текущая директория (encoder4editing):\", os.getcwd())\n",
        "\n",
        "import PIL._util\n",
        "if not hasattr(PIL._util, 'is_directory'):\n",
        "    import os\n",
        "    PIL._util.is_directory = lambda path: os.path.isdir(path)\n",
        "\n",
        "\n",
        "from argparse import Namespace\n",
        "import sys\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from PIL import ImageFile\n",
        "import glob\n",
        "import argparse\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from models.psp import pSp  # Импорт модели pSp\n",
        "\n",
        "# Трансформации для входного изображения (из папки с исходными изображениями)\n",
        "img_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "# Загрузка чекпоинта энкодера e4e из папки ./ckpts\n",
        "model_path = \"../ckpts/e4e_ffhq_encode.pt\"\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts = Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print(\"[INFO] Модель pSp (энкодер e4e) загружена.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# Ячейка 5: Обработка изображений из папки на Google Drive с входными данными\n",
        "#############################\n",
        "import zipfile\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Укажите ID входной папки на Google Drive с исходными изображениями\n",
        "# (например, ссылка вида https://drive.google.com/drive/folders/XXX, где XXX - это ID)\n",
        "input_folder_id = '15QuG_Iu8JAmVOJ-9HEJzBrk80NujHbqb'  # Замените на реальный ID входной папки\n",
        "\n",
        "# Локальные папки для временного хранения входных и выходных изображений\n",
        "temp_input_folder = './temp_input'\n",
        "os.makedirs(temp_input_folder, exist_ok=True)\n",
        "output_folder = './temp_output'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Получение списка файлов из входной папки по MIME-типу (png и jpg)\n",
        "query = f\"'{input_folder_id}' in parents and (mimeType='image/png')\"\n",
        "input_file_list = drive.ListFile({'q': query}).GetList()\n",
        "total_files = len(input_file_list)\n",
        "print(f\"[INFO] Найдено {total_files} входных изображений.\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "pbar = tqdm(total=total_files)\n",
        "for f in input_file_list:\n",
        "    pbar.update(1)\n",
        "    file_title = f['title']\n",
        "    # Скачиваем файл во временную папку\n",
        "    local_input_path = os.path.join(temp_input_folder, file_title)\n",
        "    f.GetContentFile(local_input_path)\n",
        "\n",
        "    # Открываем изображение с помощью PIL и применяем трансформации\n",
        "    try:\n",
        "        input_img = PIL.Image.open(local_input_path).convert('RGB')\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Не удалось открыть {file_title}: {e}\")\n",
        "        continue\n",
        "    transformed_image = img_transforms(input_img)\n",
        "\n",
        "    # Получаем латентное представление с помощью модели pSp\n",
        "    with torch.no_grad():\n",
        "        latents = net(transformed_image.unsqueeze(0).cuda().float(), randomize_noise=False, return_latents=True)\n",
        "        latent = latents[0].cpu().numpy()\n",
        "        latent = np.reshape(latent, (1, 18, 512))\n",
        "\n",
        "    # Применяем mapper для корректировки латентного кода (удаление волос)\n",
        "    mapper_input = latent.copy()\n",
        "    mapper_input_tensor = torch.from_numpy(mapper_input).cuda().float()\n",
        "    edited_latent_codes = latent.copy()\n",
        "    edited_latent_codes[:, :8, :] += alpha * mapper(mapper_input_tensor).to('cpu').detach().numpy()\n",
        "\n",
        "    # Генерация нового изображения с помощью генератора StyleGAN2-ada\n",
        "    outputs = model.easy_style_mixing(latent_codes=edited_latent_codes,\n",
        "                                      style_range=range(7, 18),\n",
        "                                      style_codes=latent,\n",
        "                                      mix_ratio=0.8,\n",
        "                                      **kwargs)\n",
        "    edited_img = outputs['image'][0][:, :, ::-1]  # Преобразование из BGR в RGB\n",
        "\n",
        "    # Получаем исходное изображение для получения маски (считываем локально скачанный файл)\n",
        "    origin_img = cv2.imread(local_input_path)\n",
        "\n",
        "    # Извлекаем маску волос и применяем seamlessClone\n",
        "    hair_mask = get_hair_mask(img_path=origin_img, net=parsingNet, include_hat=True, include_ear=True)\n",
        "    mask_dilate = cv2.dilate(hair_mask, kernel=np.ones((50, 50), np.uint8))\n",
        "    mask_dilate_blur = cv2.blur(mask_dilate, ksize=(30, 30))\n",
        "    mask_dilate_blur = (hair_mask + (255 - hair_mask)/255 * mask_dilate_blur).astype(np.uint8)\n",
        "    face_mask = 255 - mask_dilate_blur\n",
        "    face_mask = cv2.resize(face_mask, (origin_img.shape[1], origin_img.shape[0]))\n",
        "    idx = np.where(face_mask > 0)\n",
        "    cy = (np.min(idx[0]) + np.max(idx[0])) // 2\n",
        "    cx = (np.min(idx[1]) + np.max(idx[1])) // 2\n",
        "    center = (cx, cy)\n",
        "\n",
        "    # Применяем seamlessClone для объединения изображений\n",
        "    result_img = cv2.seamlessClone(origin_img, edited_img, face_mask[:, :, 0], center, cv2.NORMAL_CLONE)\n",
        "\n",
        "    # Сохраняем обработанное изображение в папку output_folder с расширением .png\n",
        "    output_filename = os.path.splitext(file_title)[0] + '.png'\n",
        "    local_output_path = os.path.join(output_folder, output_filename)\n",
        "    cv2.imwrite(local_output_path, result_img)\n",
        "pbar.close()\n",
        "\n",
        "print(\"[INFO] Обработка завершена. Обработанные изображения сохранены в:\", output_folder)\n",
        "\n",
        "# Создаем ZIP-архив из папки с обработанными изображениями\n",
        "zip_filename = \"processed_images.zip\"\n",
        "!zip -r {zip_filename} {output_folder}\n",
        "print(f\"[INFO] Архив {zip_filename} создан.\")\n",
        "\n",
        "# Автоматическое скачивание ZIP-архива на ПК\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "2LDeS1QzppjW",
        "outputId": "e3de405d-109a-48f4-d6d3-ae6fa2e08b5d"
      },
      "id": "2LDeS1QzppjW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Найдено 9897 входных изображений.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/9897 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up PyTorch plugin \"bias_act_plugin\"...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py311_cu124/bias_act_plugin...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Ninja is required to load C++ extensions",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-bb7e740b73de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmapper_input_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0medited_latent_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0medited_latent_codes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper_input_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Генерация нового изображения с помощью генератора StyleGAN2-ada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HairMapper/mapper/networks/level_mapper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx_structure_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructure_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_structure_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HairMapper/mapper/networks/single_mapper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'fc{idx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mW_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HairMapper/mapper/networks/single_mapper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbias_act\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HairMapper/mapper/networks/../../styleGAN2_ada_model/stylegan2_ada/torch_utils/ops/bias_act.py\u001b[0m in \u001b[0;36mbias_act\u001b[0;34m(x, b, dim, act, alpha, gain, clamp, impl)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ref'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mUSING_CUDA_TO_SPEED_UP\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_bias_act_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bias_act_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HairMapper/mapper/networks/../../styleGAN2_ada_model/stylegan2_ada/torch_utils/ops/bias_act.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'bias_act.cpp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bias_act.cu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0m_plugin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias_act_plugin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_cuda_cflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'--use_fast_math'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0m_plugin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias_act_plugin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_cuda_cflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'--use_fast_math'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HairMapper/mapper/networks/../../styleGAN2_ada_model/stylegan2_ada/torch_utils/custom_ops.py\u001b[0m in \u001b[0;36mget_plugin\u001b[0;34m(module_name, sources, **build_kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 verbose=verbose_build, sources=digest_sources, **build_kwargs)\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpp_extension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose_build\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbuild_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         ...     verbose=True)\n\u001b[1;32m   1379\u001b[0m     \"\"\"\n\u001b[0;32m-> 1380\u001b[0;31m     return _jit_compile(\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                         \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhipified_sources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                     _write_ninja_file_and_build_library(\n\u001b[0m\u001b[1;32m   1799\u001b[0m                         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m                         \u001b[0msources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0mwith_cuda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m         is_standalone: bool = False) -> None:\n\u001b[0;32m-> 1888\u001b[0;31m     \u001b[0mverify_ninja_availability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m     \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cxx_compiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mverify_ninja_availability\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1943\u001b[0m     \u001b[0;34m\"\"\"Raise ``RuntimeError`` if `ninja <https://ninja-build.org/>`_ build system is not available on the system, does nothing otherwise.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_ninja_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ninja is required to load C++ extensions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Ninja is required to load C++ extensions"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import shutil\n",
        "\n",
        "\n",
        "\n",
        "# Путь к папке с обработанными изображениями\n",
        "output_folder = './temp_output'\n",
        "\n",
        "# Получаем список файлов в папке\n",
        "all_files = sorted(os.listdir(output_folder))\n",
        "total_files = len(all_files)\n",
        "print(f\"[INFO] Всего найдено {total_files} файлов.\")\n",
        "\n",
        "# Определяем размер батча (количество изображений в одном архиве)\n",
        "batch_size = 1000\n",
        "num_batches = math.ceil(total_files / batch_size)\n",
        "print(f\"[INFO] Будет создано {num_batches} архив(ов), по {batch_size} изображений (последний архив может быть меньше).\")\n",
        "\n",
        "# Создаём архивы по батчам и инициируем скачивание каждого архива\n",
        "for batch in range(num_batches):\n",
        "    start_idx = batch * batch_size\n",
        "    end_idx = min((batch + 1) * batch_size, total_files)\n",
        "    batch_files = all_files[start_idx:end_idx]\n",
        "    zip_filename = f\"processed_images_batch_{batch+1}.zip\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_filename, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for file in batch_files:\n",
        "            file_path = os.path.join(output_folder, file)\n",
        "            # Записываем файл в архив с относительным путём (без полного пути)\n",
        "            zipf.write(file_path, arcname=file)\n",
        "\n",
        "    print(f\"[INFO] Архив {zip_filename} создан с файлами {start_idx+1} – {end_idx}.\")\n",
        "    # Скачиваем архив\n",
        "    #files.download(zip_filename)\n",
        "    shutil.move(zip_filename, f'/content/drive/MyDrive/{zip_filename}')\n"
      ],
      "metadata": {
        "id": "AJDzTpFd3jic",
        "outputId": "e3878505-b7c8-435f-c0fb-92a88736084e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AJDzTpFd3jic",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[INFO] Всего найдено 9803 файлов.\n",
            "[INFO] Будет создано 10 архив(ов), по 1000 изображений (последний архив может быть меньше).\n",
            "[INFO] Архив processed_images_batch_1.zip создан с файлами 1 – 1000.\n",
            "[INFO] Архив processed_images_batch_2.zip создан с файлами 1001 – 2000.\n",
            "[INFO] Архив processed_images_batch_3.zip создан с файлами 2001 – 3000.\n",
            "[INFO] Архив processed_images_batch_4.zip создан с файлами 3001 – 4000.\n",
            "[INFO] Архив processed_images_batch_5.zip создан с файлами 4001 – 5000.\n",
            "[INFO] Архив processed_images_batch_6.zip создан с файлами 5001 – 6000.\n",
            "[INFO] Архив processed_images_batch_7.zip создан с файлами 6001 – 7000.\n",
            "[INFO] Архив processed_images_batch_8.zip создан с файлами 7001 – 8000.\n",
            "[INFO] Архив processed_images_batch_9.zip создан с файлами 8001 – 9000.\n",
            "[INFO] Архив processed_images_batch_10.zip создан с файлами 9001 – 9803.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}