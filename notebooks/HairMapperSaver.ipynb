{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 1: Setup и загрузка моделей\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth  # Только для Colab\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Функция клонирования репозитория, если папка ещё не существует\n",
    "def clone_repo_if_not_exists(repo_url, dest_folder):\n",
    "    if os.path.exists(dest_folder):\n",
    "        print(f\"[INFO] Репозиторий уже существует: {dest_folder}\")\n",
    "        return\n",
    "    print(f\"[INFO] Клонирование репозитория: {repo_url}\")\n",
    "    subprocess.run(['git', 'clone', repo_url, dest_folder], check=True)\n",
    "    print(f\"[INFO] Репозиторий успешно клонирован в: {dest_folder}\")\n",
    "\n",
    "# Функция для скачивания файла с Google Drive, если он ещё не скачан\n",
    "def download_from_google_drive(file_id, file_dst):\n",
    "    if os.path.exists(file_dst):\n",
    "        print(f\"[INFO] Файл уже существует: {file_dst}\")\n",
    "        return\n",
    "    print(f\"[INFO] Скачивание файла в: {file_dst}\")\n",
    "    downloaded = drive.CreateFile({'id': file_id})\n",
    "    downloaded.FetchMetadata(fetch_all=True)\n",
    "    downloaded.GetContentFile(file_dst)\n",
    "    print(f\"[INFO] Файл успешно скачан: {file_dst}\")\n",
    "\n",
    "# Аутентификация в Google Drive (требуется в Colab)\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Клонируем репозиторий HairMapper, если он ещё не существует\n",
    "REPO_URL = \"https://github.com/Lunatik-006/HairMapper.git\"\n",
    "REPO_FOLDER = \"./HairMapper\"\n",
    "clone_repo_if_not_exists(REPO_URL, REPO_FOLDER)\n",
    "\n",
    "# Переходим в папку репозитория\n",
    "os.chdir(REPO_FOLDER)\n",
    "print(\"[INFO] Текущая рабочая директория:\", os.getcwd())\n",
    "\n",
    "# Загрузка чекпоинтов моделей\n",
    "checkpoints = {\n",
    "    'StyleGAN2-ada-Generator.pth': {'url': '1EsGehuEdY4z4t21o2LgW2dSsyN3rxYLJ', 'dir': './ckpts'},\n",
    "    'e4e_ffhq_encode.pt': {'url': '1cUv_reLE6k3604or78EranS7XzuVMWeO', 'dir': './ckpts'},\n",
    "    'model_ir_se50.pth': {'url': '1GIMopzrt2GE_4PG-_YxmVqTQEiaqu5L6', 'dir': './ckpts'},\n",
    "    'face_parsing.pth': {'url': '1IMsrkXA9NuCEy1ij8c8o6wCrAxkmjNPZ', 'dir': './ckpts'},\n",
    "    'vgg16.pth': {'url': '1EPhkEP_1O7ZVk66aBeKoFqf3xiM4BHH8', 'dir': './ckpts'}\n",
    "}\n",
    "for ckpt_name, info in checkpoints.items():\n",
    "    output_dir = info['dir']\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Создаем папку, если её нет\n",
    "    output_path = os.path.join(output_dir, ckpt_name)\n",
    "    download_from_google_drive(file_id=info['url'], file_dst=output_path)\n",
    "\n",
    "# Загрузка чекпоинтов классификаторов (gender/hair)\n",
    "classification_ckpt = [\n",
    "    {'url': '1SSw6vd-25OGnLAE0kuA-_VHabxlsdLXL', 'dir': './classifier/gender_classification'},\n",
    "    {'url': '1n14ckDcgiy7eu-e9XZhqQYb5025PjSpV', 'dir': './classifier/hair_classification'}\n",
    "]\n",
    "for clf in classification_ckpt:\n",
    "    output_dir = clf['dir']\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, 'classification_model.pth')\n",
    "    download_from_google_drive(file_id=clf['url'], file_dst=output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86004b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 2: Установка пакетов\n",
    "!pip install torch===2.0.0+cu117 torchvision===0.15.0+cu117 torchaudio===2.0.0+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install -r requirements.txt\n",
    "!pip install pillow==9.5.0\n",
    "!pip install \"numpy<2.0\"\n",
    "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
    "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
    "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 3: Загрузка модели mapper и тестового изображения (для отладки)\n",
    "# Здесь загружается модель mapper в папку ./mapper/checkpoints/final\n",
    "mapper_url = 'https://drive.google.com/file/d/1F3oujXbvalqEOixcAkIyURuY512nmroe'\n",
    "mapper_id = mapper_url.replace('https://drive.google.com/file/d/', '').split('/')[0]\n",
    "mapper_output_dir = './mapper/checkpoints/final'\n",
    "os.makedirs(mapper_output_dir, exist_ok=True)\n",
    "mapper_output_path = os.path.join(mapper_output_dir, 'best_model.pt')\n",
    "download_from_google_drive(file_id=mapper_id, file_dst=mapper_output_path)\n",
    "\n",
    "# Тестовое изображение загружается в папку ./test_data/origin (для отладки)\n",
    "test_img_name = '00010.png'\n",
    "test_img_id = '1f-cHWMczIyjYBWRnypi1brOpFf2skgWd'\n",
    "test_img_dir = './test_data/origin'\n",
    "os.makedirs(test_img_dir, exist_ok=True)\n",
    "test_img_path = os.path.join(test_img_dir, test_img_name)\n",
    "download_from_google_drive(file_id=test_img_id, file_dst=test_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 4: Переход в папку encoder4editing и загрузка модели pSp (энкодер e4e)\n",
    "os.chdir('./encoder4editing')\n",
    "print(\"[INFO] Текущая директория (encoder4editing):\", os.getcwd())\n",
    "\n",
    "from argparse import Namespace\n",
    "import sys\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from PIL import ImageFile\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from models.psp import pSp  # Импорт модели pSp\n",
    "\n",
    "# Трансформации для входного изображения (из папки с исходными изображениями)\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "# Загрузка чекпоинта энкодера e4e из папки ./ckpts\n",
    "model_path = \"../ckpts/e4e_ffhq_encode.pt\"\n",
    "ckpt = torch.load(model_path, map_location='cpu')\n",
    "opts = ckpt['opts']\n",
    "opts['checkpoint_path'] = model_path\n",
    "opts = Namespace(**opts)\n",
    "net = pSp(opts)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "print(\"[INFO] Модель pSp (энкодер e4e) загружена.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 5: Обработка изображений из папки на Google Drive с входными данными\n",
    "# Этот блок считывает изображения из указанной входной папки на Google Drive,\n",
    "# обрабатывает их (удаление волос) и сохраняет результаты в локальную папку.\n",
    "# В конце результаты упаковываются в ZIP-архив и автоматически скачиваются на ПК.\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Укажите ID входной папки на Google Drive с исходными изображениями\n",
    "# (напр., ссылка вида https://drive.google.com/drive/folders/XXX, где XXX - это ID)\n",
    "input_folder_id = 'YOUR_INPUT_FOLDER_ID'  # Замените на реальный ID входной папки\n",
    "\n",
    "# Локальные папки для временного хранения входных и выходных изображений\n",
    "temp_input_folder = './temp_input'\n",
    "os.makedirs(temp_input_folder, exist_ok=True)\n",
    "output_folder = './temp_output'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Получение списка файлов из входной папки по MIME-типу (png и jpg)\n",
    "query = f\"'{input_folder_id}' in parents and (mimeType='image/png' or mimeType='image/jpeg')\"\n",
    "input_file_list = drive.ListFile({'q': query}).GetList()\n",
    "total_files = len(input_file_list)\n",
    "print(f\"[INFO] Найдено {total_files} входных изображений.\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "pbar = tqdm(total=total_files)\n",
    "for f in input_file_list:\n",
    "    pbar.update(1)\n",
    "    file_title = f['title']\n",
    "    # Скачиваем файл во временную папку\n",
    "    local_input_path = os.path.join(temp_input_folder, file_title)\n",
    "    f.GetContentFile(local_input_path)\n",
    "    \n",
    "    # Открываем изображение с помощью PIL и применяем трансформации\n",
    "    try:\n",
    "        input_img = PIL.Image.open(local_input_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Не удалось открыть {file_title}: {e}\")\n",
    "        continue\n",
    "    transformed_image = img_transforms(input_img)\n",
    "    \n",
    "    # Получаем латентное представление с помощью модели pSp\n",
    "    with torch.no_grad():\n",
    "        latents = net(transformed_image.unsqueeze(0).cuda().float(), randomize_noise=False, return_latents=True)\n",
    "        latent = latents[0].cpu().numpy()\n",
    "        latent = np.reshape(latent, (1, 18, 512))\n",
    "    \n",
    "    # Применяем mapper для корректировки латентного кода (удаление волос)\n",
    "    mapper_input = latent.copy()\n",
    "    mapper_input_tensor = torch.from_numpy(mapper_input).cuda().float()\n",
    "    edited_latent_codes = latent\n",
    "    edited_latent_codes[:, :8, :] += alpha * mapper(mapper_input_tensor).to('cpu').detach().numpy()\n",
    "    \n",
    "    # Генерация нового изображения с помощью генератора StyleGAN2-ada\n",
    "    outputs = model.easy_style_mixing(latent_codes=edited_latent_codes,\n",
    "                                      style_range=range(7,18),\n",
    "                                      style_codes=latent,\n",
    "                                      mix_ratio=0.8,\n",
    "                                      **kwargs)\n",
    "    edited_img = outputs['image'][0][:, :, ::-1]  # Преобразование из BGR в RGB\n",
    "    \n",
    "    # Получаем исходное изображение для получения маски (считываем локально скачанный файл)\n",
    "    origin_img = cv2.imread(local_input_path)\n",
    "    \n",
    "    # Извлекаем маску волос и применяем seamlessClone\n",
    "    hair_mask = get_hair_mask(img_path=origin_img, net=parsingNet, include_hat=True, include_ear=True)\n",
    "    mask_dilate = cv2.dilate(hair_mask, kernel=np.ones((50, 50), np.uint8))\n",
    "    mask_dilate_blur = cv2.blur(mask_dilate, ksize=(30,30))\n",
    "    mask_dilate_blur = (hair_mask + (255 - hair_mask)/255 * mask_dilate_blur).astype(np.uint8)\n",
    "    face_mask = 255 - mask_dilate_blur\n",
    "    face_mask = cv2.resize(face_mask, (origin_img.shape[1], origin_img.shape[0]))\n",
    "    idx = np.where(face_mask > 0)\n",
    "    cy = (np.min(idx[0]) + np.max(idx[0])) // 2\n",
    "    cx = (np.min(idx[1]) + np.max(idx[1])) // 2\n",
    "    center = (cx, cy)\n",
    "    \n",
    "    # Применяем seamlessClone для объединения изображений\n",
    "    result_img = cv2.seamlessClone(origin_img, edited_img, face_mask[:, :, 0], center, cv2.NORMAL_CLONE)\n",
    "    \n",
    "    # Сохраняем обработанное изображение в папку output_folder с расширением .png\n",
    "    output_filename = os.path.splitext(file_title)[0] + '.png'\n",
    "    local_output_path = os.path.join(output_folder, output_filename)\n",
    "    cv2.imwrite(local_output_path, result_img)\n",
    "pbar.close()\n",
    "\n",
    "print(\"[INFO] Обработка завершена. Обработанные изображения сохранены в:\", output_folder)\n",
    "\n",
    "# Создаем ZIP-архив из папки с обработанными изображениями\n",
    "zip_filename = \"processed_images.zip\"\n",
    "!zip -r {zip_filename} {output_folder}\n",
    "print(f\"[INFO] Архив {zip_filename} создан.\")\n",
    "\n",
    "# Автоматическое скачивание ZIP-архива на ПК\n",
    "files.download(zip_filename)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
