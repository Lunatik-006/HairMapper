{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e318682",
   "metadata": {},
   "source": [
    "Setup: Клонирование репозитория и загрузка чекпоинтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e54f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 1: Setup\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth  # Если запускаете в Colab; для локального запуска удалите\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Функция клонирования репозитория, если папка еще не существует\n",
    "def clone_repo_if_not_exists(repo_url, dest_folder):\n",
    "    if os.path.exists(dest_folder):\n",
    "        print(f\"[INFO] Репозиторий уже существует: {dest_folder}\")\n",
    "        return\n",
    "    print(f\"[INFO] Клонирование репозитория: {repo_url}\")\n",
    "    subprocess.run(['git', 'clone', repo_url, dest_folder], check=True)\n",
    "    print(f\"[INFO] Репозиторий успешно клонирован в: {dest_folder}\")\n",
    "\n",
    "# Функция для скачивания файла с Google Drive, если его еще нет\n",
    "def download_from_google_drive(file_id, file_dst):\n",
    "    if os.path.exists(file_dst):\n",
    "        print(f\"[INFO] Файл уже существует: {file_dst}\")\n",
    "        return\n",
    "    print(f\"[INFO] Скачивание файла в: {file_dst}\")\n",
    "    downloaded = drive.CreateFile({'id': file_id})\n",
    "    downloaded.FetchMetadata(fetch_all=True)\n",
    "    downloaded.GetContentFile(file_dst)\n",
    "    print(f\"[INFO] Файл успешно скачан: {file_dst}\")\n",
    "\n",
    "# Аутентификация в Google Drive (в Colab требуется, даже если папка публичная)\n",
    "auth.authenticate_user()  # Если запускаете в Colab\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Клонируем репозиторий HairMapper, если он еще не клонирован\n",
    "REPO_URL = \"https://github.com/Lunatik-006/HairMapper.git\"\n",
    "REPO_FOLDER = \"./HairMapper\"\n",
    "clone_repo_if_not_exists(REPO_URL, REPO_FOLDER)\n",
    "\n",
    "# Переходим в папку репозитория\n",
    "os.chdir(REPO_FOLDER)\n",
    "print(\"[INFO] Текущая рабочая директория:\", os.getcwd())\n",
    "\n",
    "# ==================== Загрузка чекпоинтов моделей ====================\n",
    "# Словарь с данными для чекпоинтов: имя файла, ID Google Drive и папка назначения\n",
    "checkpoints = {\n",
    "    'StyleGAN2-ada-Generator.pth': {\n",
    "        'url': '1EsGehuEdY4z4t21o2LgW2dSsyN3rxYLJ',\n",
    "        'dir': './ckpts'\n",
    "    },\n",
    "    'e4e_ffhq_encode.pt': {\n",
    "        'url': '1cUv_reLE6k3604or78EranS7XzuVMWeO',\n",
    "        'dir': './ckpts'\n",
    "    },\n",
    "    'model_ir_se50.pth': {\n",
    "        'url': '1GIMopzrt2GE_4PG-_YxmVqTQEiaqu5L6',\n",
    "        'dir': './ckpts'\n",
    "    },\n",
    "    'face_parsing.pth': {\n",
    "        'url': '1IMsrkXA9NuCEy1ij8c8o6wCrAxkmjNPZ',\n",
    "        'dir': './ckpts'\n",
    "    },\n",
    "    'vgg16.pth': {\n",
    "        'url': '1EPhkEP_1O7ZVk66aBeKoFqf3xiM4BHH8',\n",
    "        'dir': './ckpts'\n",
    "    }\n",
    "}\n",
    "\n",
    "for ckpt_name, info in checkpoints.items():\n",
    "    output_dir = info['dir']\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, ckpt_name)\n",
    "    download_from_google_drive(file_id=info['url'], file_dst=output_path)\n",
    "\n",
    "# Загрузка чекпоинтов классификаторов (для gender/hair)\n",
    "classification_ckpt = [\n",
    "    {'url': '1SSw6vd-25OGnLAE0kuA-_VHabxlsdLXL', 'dir': './classifier/gender_classification'},\n",
    "    {'url': '1n14ckDcgiy7eu-e9XZhqQYb5025PjSpV', 'dir': './classifier/hair_classification'}\n",
    "]\n",
    "for clf in classification_ckpt:\n",
    "    output_dir = clf['dir']\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, 'classification_model.pth')\n",
    "    download_from_google_drive(file_id=clf['url'], file_dst=output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba4599c",
   "metadata": {},
   "source": [
    "Установка пакетов и зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02942530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 2: Установка пакетов\n",
    "# Если запускаете в Colab, используйте команды !pip install и !wget.\n",
    "# В локальной среде выполните установку через командную строку или Python.\n",
    "\n",
    "# Установка PyTorch с поддержкой CUDA (если у вас NVIDIA GPU) или CPU-версия\n",
    "!pip install torch===2.0.0+cu117 torchvision===0.15.0+cu117 torchaudio===2.0.0+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# Установка остальных зависимостей из requirements.txt\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Понижение версии Pillow до 9.5.0 для совместимости с torchvision и numpy<2.0 для совместимости с pillow\n",
    "!pip install pillow==9.5.0\n",
    "!pip install \"numpy<2.0\"\n",
    "\n",
    "# Установка Ninja (для сборки CUDA расширений, если требуется)\n",
    "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
    "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
    "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbfe925",
   "metadata": {},
   "source": [
    "3. Загрузка модели mapper и тестового изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dbe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 3: Загрузка предобученной модели mapper и тестового изображения\n",
    "\n",
    "# Загрузка модели mapper (папка: ./mapper/checkpoints/final)\n",
    "mapper_url = 'https://drive.google.com/file/d/1F3oujXbvalqEOixcAkIyURuY512nmroe'\n",
    "# Преобразуем URL для получения ID\n",
    "mapper_id = mapper_url.replace('https://drive.google.com/file/d/', '').split('/')[0]\n",
    "mapper_output_dir = './mapper/checkpoints/final'\n",
    "os.makedirs(mapper_output_dir, exist_ok=True)\n",
    "mapper_output_path = os.path.join(mapper_output_dir, 'best_model.pt')\n",
    "download_from_google_drive(file_id=mapper_id, file_dst=mapper_output_path)\n",
    "\n",
    "# Загрузка тестового изображения (сохранится в ./test_data/origin)\n",
    "test_img_name = '00010.png'\n",
    "test_img_id = '1f-cHWMczIyjYBWRnypi1brOpFf2skgWd'\n",
    "test_img_dir = './test_data/origin'\n",
    "os.makedirs(test_img_dir, exist_ok=True)\n",
    "test_img_path = os.path.join(test_img_dir, test_img_name)\n",
    "download_from_google_drive(file_id=test_img_id, file_dst=test_img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746543a",
   "metadata": {},
   "source": [
    "4. Переход в папку encoder4editing, Импорт модулей и загрузка модели pSp (энкодер e4e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переход в папку encoder4editing\n",
    "# (Убедитесь, что папка encoder4editing присутствует в репозитории или клонируйте её, если требуется)\n",
    "os.chdir('./encoder4editing')\n",
    "print(\"[INFO] Текущая директория (encoder4editing):\", os.getcwd())\n",
    "# Импорт модулей и загрузка модели pSp (энкодер e4e)\n",
    "from argparse import Namespace\n",
    "import sys\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from PIL import ImageFile\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from models.psp import pSp  # Импорт модели pSp\n",
    "\n",
    "# Определяем трансформации для входного изображения\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Загружаем чекпоинт для энкодера e4e (файл из ./ckpts)\n",
    "model_path = \"../ckpts/e4e_ffhq_encode.pt\"\n",
    "ckpt = torch.load(model_path, map_location='cpu')\n",
    "opts = ckpt['opts']\n",
    "opts['checkpoint_path'] = model_path\n",
    "opts = Namespace(**opts)\n",
    "net = pSp(opts)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "print(\"[INFO] Модель pSp (энкодер e4e) загружена.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7c30c",
   "metadata": {},
   "source": [
    "5. Кодирование изображений: создание латентных кодов для тестовых изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 5: Кодирование изображений (из папки с исходными изображениями в папку с латентными кодами)\n",
    "# Исходные изображения находятся в папке: ../test_data/origin\n",
    "# Латентные коды будут сохраняться в папке: ../test_data/code\n",
    "\n",
    "data_dir = '../test_data'\n",
    "origin_dir = os.path.join(data_dir, 'origin')  # Папка с исходными изображениями (отсюда вы можете вручную проверять изображения)\n",
    "code_dir = os.path.join(data_dir, 'code')        # Папка для сохранения латентных кодов\n",
    "os.makedirs(code_dir, exist_ok=True)\n",
    "\n",
    "def run_on_batch(inputs, net):\n",
    "    # Функция для получения латентного представления\n",
    "    latents = net(inputs.to(\"cuda\").float(), randomize_noise=False, return_latents=True)\n",
    "    return latents\n",
    "\n",
    "# Обработка изображений: для каждого файла (png/jpg) из origin_dir,\n",
    "# если соответствующий файл с латентным кодом отсутствует в code_dir, создаем его.\n",
    "for file_path in glob.glob(os.path.join(origin_dir, '*.png')) + glob.glob(os.path.join(origin_dir, '*.jpg')):\n",
    "    name = os.path.basename(file_path)[:-4]\n",
    "    code_path = os.path.join(code_dir, f'{name}.npy')\n",
    "    if os.path.exists(code_path):\n",
    "        print(f\"[INFO] Латентный код уже существует: {code_path}\")\n",
    "        continue\n",
    "    input_image = PIL.Image.open(file_path).convert('RGB')\n",
    "    transformed_image = img_transforms(input_image)\n",
    "    with torch.no_grad():\n",
    "        latents = run_on_batch(transformed_image.unsqueeze(0), net)\n",
    "        latent = latents[0].cpu().numpy()\n",
    "        latent = np.reshape(latent, (1, 18, 512))\n",
    "        np.save(code_path, latent)\n",
    "        print(f\"[INFO] Латентный код сохранен: {code_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab123736",
   "metadata": {},
   "source": [
    "6. Запуск удаления волос с изображения с использованием mapper и генератора StyleGAN2-ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 6: Удаление волос (выполнение стиля смешивания с mapper)\n",
    "# Входные данные:\n",
    "# - Латентные коды из папки: ./test_data/code\n",
    "# - Исходные изображения из папки: ./test_data/origin\n",
    "# Результаты сохраняются в папку: ./test_data/mapper_res\n",
    "\n",
    "os.chdir('../')  # Возвращаемся в корневую папку репозитория\n",
    "print(\"[INFO] Текущая директория:\", os.getcwd())\n",
    "\n",
    "import cv2\n",
    "import argparse\n",
    "from styleGAN2_ada_model.stylegan2_ada_generator import StyleGAN2adaGenerator\n",
    "from tqdm import tqdm\n",
    "from classifier.src.feature_extractor.hair_mask_extractor import get_hair_mask, get_parsingNet\n",
    "from mapper.networks.level_mapper import LevelMapper\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from diffuse.inverter_remove_hair import InverterRemoveHair  # если используется\n",
    "\n",
    "# Параметры моделей и путей\n",
    "model_name = 'stylegan2_ada'\n",
    "latent_space_type = 'wp'\n",
    "data_dir = './test_data'\n",
    "origin_img_dir = os.path.join(data_dir, 'origin')    # Исходные изображения (для ручной проверки – см. папку)\n",
    "code_dir = os.path.join(data_dir, 'code')              # Латентные коды (см. папку)\n",
    "res_dir = os.path.join(data_dir, 'mapper_res')         # Результаты обработки будут сохраняться здесь\n",
    "os.makedirs(res_dir, exist_ok=True)\n",
    "\n",
    "# Инициализация генератора StyleGAN2-ada\n",
    "print(\"[INFO] Инициализация генератора...\")\n",
    "model = StyleGAN2adaGenerator(model_name, logger=None, truncation_psi=1.0)\n",
    "\n",
    "# Инициализация mapper (удаление волос)\n",
    "mapper = LevelMapper(input_dim=512).eval().cuda()\n",
    "ckpt = torch.load('./mapper/checkpoints/final/best_model.pt')\n",
    "alpha = float(ckpt['alpha']) * 1.2  # Коэффициент изменения\n",
    "mapper.load_state_dict(ckpt['state_dict'], strict=True)\n",
    "kwargs = {'latent_space_type': latent_space_type}\n",
    "\n",
    "# Загрузка модели для парсинга лица (используется для извлечения маски волос)\n",
    "parsingNet = get_parsingNet(save_pth='./ckpts/face_parsing.pth')\n",
    "\n",
    "# Если используется дополнительная инверсия для удаления волос (можно отключить, если не нужно)\n",
    "inverter = InverterRemoveHair(\n",
    "    model_name,\n",
    "    Generator=model,\n",
    "    learning_rate=0.01,\n",
    "    reconstruction_loss_weight=1.0,\n",
    "    perceptual_loss_weight=5e-5,\n",
    "    truncation_psi=1.0,\n",
    "    logger=None\n",
    ")\n",
    "\n",
    "# Процесс обработки латентных кодов\n",
    "code_list = glob.glob(os.path.join(code_dir, '*.npy'))\n",
    "total_num = len(code_list)\n",
    "print(f\"[INFO] Обработка {total_num} образцов.\")\n",
    "pbar = tqdm(total=total_num)\n",
    "for code_path in code_list:\n",
    "    pbar.update(1)\n",
    "    name = os.path.basename(code_path)[:-4]\n",
    "    # Определяем путь к исходному изображению (png или jpg)\n",
    "    f_path_png = os.path.join(origin_img_dir, f'{name}.png')\n",
    "    f_path_jpg = os.path.join(origin_img_dir, f'{name}.jpg')\n",
    "    if os.path.exists(os.path.join(res_dir, f'{name}.png')):\n",
    "        continue\n",
    "    if os.path.exists(f_path_png):\n",
    "        origin_img_path = f_path_png\n",
    "    elif os.path.exists(f_path_jpg):\n",
    "        origin_img_path = f_path_jpg\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Загрузка латентного кода и его преобразование\n",
    "    latent_codes_origin = np.reshape(np.load(code_path), (1, 18, 512))\n",
    "    mapper_input = latent_codes_origin.copy()\n",
    "    mapper_input_tensor = torch.from_numpy(mapper_input).cuda().float()\n",
    "    edited_latent_codes = latent_codes_origin\n",
    "    edited_latent_codes[:, :8, :] += alpha * mapper(mapper_input_tensor).to('cpu').detach().numpy()\n",
    "\n",
    "    # Загрузка исходного изображения (для проверки – см. папку origin)\n",
    "    origin_img = cv2.imread(origin_img_path)\n",
    "\n",
    "    # Генерация нового изображения с помощью функции easy_style_mixing\n",
    "    outputs = model.easy_style_mixing(latent_codes=edited_latent_codes,\n",
    "                                      style_range=range(7, 18),\n",
    "                                      style_codes=latent_codes_origin,\n",
    "                                      mix_ratio=0.8,\n",
    "                                      **kwargs)\n",
    "    edited_img = outputs['image'][0][:, :, ::-1]  # Перевод из BGR в RGB\n",
    "\n",
    "    # Получаем маску волос (сохраненные результаты можно проверить в папке с исходными изображениями)\n",
    "    hair_mask = get_hair_mask(img_path=origin_img, net=parsingNet, include_hat=True, include_ear=True)\n",
    "    mask_dilate = cv2.dilate(hair_mask, kernel=np.ones((50, 50), np.uint8))\n",
    "    mask_dilate_blur = cv2.blur(mask_dilate, ksize=(30, 30))\n",
    "    mask_dilate_blur = (hair_mask + (255 - hair_mask) / 255 * mask_dilate_blur).astype(np.uint8)\n",
    "    face_mask = 255 - mask_dilate_blur\n",
    "    face_mask = cv2.resize(face_mask, (origin_img.shape[1], origin_img.shape[0]))\n",
    "\n",
    "    # Вычисление центра области для seamlessClone (на основе маски)\n",
    "    idx = np.where(face_mask > 0)\n",
    "    cy = (np.min(idx[0]) + np.max(idx[0])) // 2\n",
    "    cx = (np.min(idx[1]) + np.max(idx[1])) // 2\n",
    "    center = (cx, cy)\n",
    "\n",
    "    res_save_path = os.path.join(res_dir, f'{name}.png')\n",
    "    # Применяем seamlessClone для аккуратного объединения областей\n",
    "    mixed_clone = cv2.seamlessClone(origin_img, edited_img, face_mask[:, :, 0], center, cv2.NORMAL_CLONE)\n",
    "    cv2.imwrite(res_save_path, mixed_clone)\n",
    "pbar.close()\n",
    "print(\"[INFO] Обработка завершена.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2863109",
   "metadata": {},
   "source": [
    "7. Визуализация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 7: Визуализация результатов\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Вывод результатов обработки. Изображения сохраняются в папке: ./test_data/mapper_res\n",
    "for res_path in glob.glob('./test_data/mapper_res/*'):\n",
    "    res_img = cv2.imread(res_path)[:, :, ::-1]  # Конвертация из BGR в RGB\n",
    "    res_im = Image.fromarray(res_img)\n",
    "    display(res_im)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
