{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setup"
      ],
      "metadata": {
        "id": "SEvU2up7WH4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "code",
        "id": "6vaK0s48v8_w",
        "collapsed": true,
        "outputId": "5e40f06c-fcf0-42e0-a960-0cc7b9de3d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HairMapper'...\n",
            "remote: Enumerating objects: 415, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 415 (delta 21), reused 18 (delta 18), pack-reused 373 (from 1)\u001b[K\n",
            "Receiving objects: 100% (415/415), 38.38 MiB | 17.23 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Please wait util all models are downloaded...\n"
          ]
        }
      ],
      "source": [
        "#@title Setup\n",
        "!git clone https://github.com/oneThousand1000/HairMapper\n",
        "import os\n",
        "os.chdir('./HairMapper')\n",
        "\n",
        "# ==================== download checkpoint ====================\n",
        "!pip install gdown\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "print('Please wait util all models are downloaded...')\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "def download_from_google_drive(file_id,file_dst):\n",
        "  downloaded = drive.CreateFile({'id':file_id})\n",
        "  downloaded.FetchMetadata(fetch_all=True)\n",
        "  downloaded.GetContentFile(file_dst)\n",
        "\n",
        "checkpoints ={\n",
        "    'StyleGAN2-ada-Generator.pth':\n",
        "    {\n",
        "        'url':'1EsGehuEdY4z4t21o2LgW2dSsyN3rxYLJ',\n",
        "        'dir': './ckpts'\n",
        "    },\n",
        "    'e4e_ffhq_encode.pt':\n",
        "    {\n",
        "        'url':'1cUv_reLE6k3604or78EranS7XzuVMWeO',\n",
        "        'dir': './ckpts'\n",
        "    },\n",
        "    'model_ir_se50.pth':\n",
        "    {\n",
        "        'url':'1GIMopzrt2GE_4PG-_YxmVqTQEiaqu5L6',\n",
        "        'dir': './ckpts'\n",
        "    },\n",
        "    'face_parsing.pth':\n",
        "    {\n",
        "        'url':'1IMsrkXA9NuCEy1ij8c8o6wCrAxkmjNPZ',\n",
        "        'dir': './ckpts'\n",
        "    },\n",
        "    'vgg16.pth':\n",
        "    {\n",
        "        'url':'1EPhkEP_1O7ZVk66aBeKoFqf3xiM4BHH8',\n",
        "        'dir': './ckpts'\n",
        "    }\n",
        "}\n",
        "for ckpt in checkpoints:\n",
        "  name = ckpt\n",
        "  url = checkpoints[name]['url']\n",
        "  output_dir = checkpoints[name]['dir']\n",
        "  os.makedirs(output_dir,exist_ok=True)\n",
        "  output_path = os.path.join(output_dir,name)\n",
        "  #gdown.download(url=url,output=output_path,quiet=False) # bug\n",
        "  download_from_google_drive(file_id=url, file_dst=output_path)\n",
        "\n",
        "classification_ckpt =[\n",
        "        {'url':'1SSw6vd-25OGnLAE0kuA-_VHabxlsdLXL',\n",
        "        'dir': './classifier/gender_classification'},\n",
        "        {'url':'1n14ckDcgiy7eu-e9XZhqQYb5025PjSpV',\n",
        "        'dir': './classifier/hair_classification'}\n",
        "]\n",
        "for clf_ckpt_dict in classification_ckpt:\n",
        "  name = 'classification_model.pth'\n",
        "  url = clf_ckpt_dict['url']\n",
        "  output_dir = clf_ckpt_dict['dir']\n",
        "  os.makedirs(output_dir,exist_ok=True)\n",
        "  output_path = os.path.join(output_dir,name)\n",
        "  #gdown.download(url=url,output=output_path,quiet=False)\n",
        "  download_from_google_drive(file_id=url, file_dst=output_path)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== install packages ====================\n",
        "!pip install torch===2.0.0+cu117 torchvision===0.15.0+cu117 torchaudio===2.0.0+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -r requirements.txt\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ],
      "metadata": {
        "id": "7raPzfYlJs3K",
        "outputId": "6d260985-3772-4b46-e650-59120104d70f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===2.0.0+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torch-2.0.0%2Bcu117-cp311-cp311-linux_x86_64.whl (1843.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m449.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision===0.15.0+cu117\n",
            "  Using cached https://download.pytorch.org/whl/cu117/torchvision-0.15.0%2Bcu117-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "Collecting torchaudio===2.0.0+cu117\n",
            "  Using cached https://download.pytorch.org/whl/cu117/torchaudio-2.0.0%2Bcu117-cp311-cp311-linux_x86_64.whl (4.4 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (4.13.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (3.1.6)\n",
            "Collecting triton==2.0.0 (from torch===2.0.0+cu117)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision===0.15.0+cu117) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision===0.15.0+cu117) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision===0.15.0+cu117) (11.1.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch===2.0.0+cu117) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch===2.0.0+cu117)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch===2.0.0+cu117) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch===2.0.0+cu117) (1.3.0)\n",
            "Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed lit-18.1.8 torch-2.0.0+cu117 torchaudio-2.0.0+cu117 torchvision-0.15.0+cu117 triton-2.0.0\n",
            "Collecting tqdm==4.60.0 (from -r requirements.txt (line 1))\n",
            "  Using cached tqdm-4.60.0-py2.py3-none-any.whl.metadata (57 kB)\n",
            "Collecting requests==2.25.1 (from -r requirements.txt (line 2))\n",
            "  Using cached requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting matplotlib==3.4.1 (from -r requirements.txt (line 3))\n",
            "  Using cached matplotlib-3.4.1.tar.gz (37.3 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyYAML==5.4.1 (from -r requirements.txt (line 4))\n",
            "  Using cached PyYAML-5.4.1.tar.gz (175 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "--2025-04-04 14:19:30--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250404T141930Z&X-Amz-Expires=300&X-Amz-Signature=4bedcd6f92c32a5b0e30a4cbda9b0acf454c668a7e6613bb9c6c5770297b891d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-04 14:19:30--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250404T141930Z&X-Amz-Expires=300&X-Amz-Signature=4bedcd6f92c32a5b0e30a4cbda9b0acf454c668a7e6613bb9c6c5770297b891d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip’\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-04-04 14:19:30 (5.94 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "replace /usr/local/bin/ninja? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: /usr/local/bin/ninja    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: pre-trained models access\n",
        "\n",
        "Please fill out this form for **pre-trained models access**: https://forms.gle/a5pRbE3yxEr7sZDm7\n",
        "\n",
        "Then fill out the mapper_url with the url of [Final HairMapper]\n",
        "\n"
      ],
      "metadata": {
        "id": "Vf0wbY4dVOqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapper_url = 'https://drive.google.com/file/d/1F3oujXbvalqEOixcAkIyURuY512nmroe' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "h0glHNtLWQTN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: download pre-trained model and test image"
      ],
      "metadata": {
        "id": "By8BOsUlWlVf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "code",
        "id": "OSnXgjN8z69C"
      },
      "outputs": [],
      "source": [
        "#@title Download Pretrain Models\n",
        "\n",
        "name = 'best_model.pt'\n",
        "mapper_url = mapper_url.replace('https://drive.google.com/file/d/','')\n",
        "output_dir = './mapper/checkpoints/final'\n",
        "os.makedirs(output_dir,exist_ok=True)\n",
        "output_path = os.path.join(output_dir,name)\n",
        "download_from_google_drive(file_id=mapper_url, file_dst=output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1kPIBkM64Vkq"
      },
      "outputs": [],
      "source": [
        "#@title Download test image\n",
        "name = '00006.png'\n",
        "url = '1UlROI0W8sPXUbufzQ0cm8yi9dzX9V6vd'\n",
        "output_dir = './test_data/origin'\n",
        "os.makedirs(output_dir,exist_ok=True)\n",
        "output_path = os.path.join(output_dir,name)\n",
        "download_from_google_drive(file_id=url, file_dst=output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Run encoder"
      ],
      "metadata": {
        "id": "C-kaQzhWWvPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./encoder4editing')"
      ],
      "metadata": {
        "id": "iiZkiA0jUSGH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please put the real images to **./test_data/origin** (examplar data can be found in ./test_data/origin/00006.png).\n",
        "\n"
      ],
      "metadata": {
        "id": "OYXDMXr6VomP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0\"\n"
      ],
      "metadata": {
        "id": "olaUqUdKOdbe",
        "outputId": "b9ccff15-cbe8-4d25-a4dd-dbcb0fde90a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/18.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/18.3 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/18.3 MB\u001b[0m \u001b[31m139.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m17.2/18.3 MB\u001b[0m \u001b[31m217.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m18.2/18.3 MB\u001b[0m \u001b[31m214.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7tgDxBy8NyZ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "cellView": "code",
        "id": "g48Gc41R49C-"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "import sys\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from PIL import ImageFile\n",
        "import glob\n",
        "import os\n",
        "import argparse\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from models.psp import pSp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_on_batch(inputs, net):\n",
        "    latents = net(inputs.to(\"cuda\").float(), randomize_noise=False, return_latents=True)\n",
        "    return latents\n"
      ],
      "metadata": {
        "id": "oM97v_b7XG4G"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_transforms = transforms.Compose([\n",
        "          transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]\n",
        "            )\n",
        "model_path = \"../ckpts/e4e_ffhq_encode.pt\"\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts= Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()"
      ],
      "metadata": {
        "id": "cRgwRCs9XLan",
        "outputId": "50dfcf2d-3dff-4007-c9db-58a93f9ab161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading e4e over the pSp framework from checkpoint: ../ckpts/e4e_ffhq_encode.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pSp(\n",
              "  (encoder): Encoder4Editing(\n",
              "    (input_layer): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): PReLU(num_parameters=64)\n",
              "    )\n",
              "    (body): Sequential(\n",
              "      (0): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=64)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=64)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=64)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): bottleneck_IR_SE(\n",
              "        (shortcut_layer): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=128)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=128)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=128)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=128)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): bottleneck_IR_SE(\n",
              "        (shortcut_layer): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (12): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (13): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (14): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (15): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (16): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (17): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (18): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (19): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (20): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=256)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (21): bottleneck_IR_SE(\n",
              "        (shortcut_layer): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=512)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (22): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=512)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (23): bottleneck_IR_SE(\n",
              "        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "        (res_layer): Sequential(\n",
              "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (2): PReLU(num_parameters=512)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): SEModule(\n",
              "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (sigmoid): Sigmoid()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (styles): ModuleList(\n",
              "      (0-2): 3 x GradualStyleBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (3): LeakyReLU(negative_slope=0.01)\n",
              "          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (5): LeakyReLU(negative_slope=0.01)\n",
              "          (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (7): LeakyReLU(negative_slope=0.01)\n",
              "        )\n",
              "        (linear): EqualLinear(512, 512)\n",
              "      )\n",
              "      (3-6): 4 x GradualStyleBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (3): LeakyReLU(negative_slope=0.01)\n",
              "          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (5): LeakyReLU(negative_slope=0.01)\n",
              "          (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (7): LeakyReLU(negative_slope=0.01)\n",
              "          (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (9): LeakyReLU(negative_slope=0.01)\n",
              "        )\n",
              "        (linear): EqualLinear(512, 512)\n",
              "      )\n",
              "      (7-17): 11 x GradualStyleBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (3): LeakyReLU(negative_slope=0.01)\n",
              "          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (5): LeakyReLU(negative_slope=0.01)\n",
              "          (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (7): LeakyReLU(negative_slope=0.01)\n",
              "          (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (9): LeakyReLU(negative_slope=0.01)\n",
              "          (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (11): LeakyReLU(negative_slope=0.01)\n",
              "        )\n",
              "        (linear): EqualLinear(512, 512)\n",
              "      )\n",
              "    )\n",
              "    (latlayer1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (latlayer2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (face_pool): AdaptiveAvgPool2d(output_size=(256, 256))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '../test_data'\n",
        "file_dir = os.path.join(data_dir,'origin')\n",
        "code_dir = os.path.join(data_dir,'code')\n",
        "if not os.path.exists(code_dir):\n",
        "    os.mkdir(code_dir)\n",
        "for file_path in glob.glob(os.path.join(file_dir,'*.png'))+glob.glob(os.path.join(file_dir,'*.jpg')):\n",
        "    name = os.path.basename(file_path)[:-4]\n",
        "    code_path =os.path.join(code_dir,f'{name}.npy')\n",
        "    if os.path.exists(code_path):\n",
        "        continue\n",
        "    input_image = PIL.Image.open(file_path)\n",
        "    transformed_image = img_transforms(input_image)\n",
        "    with torch.no_grad():\n",
        "        latents = run_on_batch(transformed_image.unsqueeze(0), net)\n",
        "        latent = latents[0].cpu().numpy()\n",
        "        latent = np.reshape(latent,(1,18,512))\n",
        "        np.save(code_path,latent)\n",
        "        print(f'save to {code_path}')\n"
      ],
      "metadata": {
        "id": "kEKEdnVUXc7y",
        "outputId": "0f2b1e69-6074-40ed-ba83-966c9c634a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bb50855ef576>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtransformed_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Run HairMaper"
      ],
      "metadata": {
        "id": "e1RcV6nhWz9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('../')"
      ],
      "metadata": {
        "id": "t_N3sGzZUT-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import argparse\n",
        "import cv2\n",
        "from styleGAN2_ada_model.stylegan2_ada_generator import StyleGAN2adaGenerator\n",
        "from tqdm import tqdm\n",
        "from classifier.src.feature_extractor.hair_mask_extractor import get_hair_mask, get_parsingNet\n",
        "from mapper.networks.level_mapper import LevelMapper\n",
        "import torch\n",
        "import glob\n",
        "from diffuse.inverter_remove_hair import InverterRemoveHair\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "import os\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {
        "id": "XPrzEeq8WmfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'stylegan2_ada'\n",
        "latent_space_type = 'wp'\n",
        "data_dir = './test_data'\n",
        "print(f'Initializing generator.')\n",
        "model = StyleGAN2adaGenerator(model_name, logger=None, truncation_psi=1.0)\n",
        "\n",
        "mapper = LevelMapper(input_dim=512).eval().cuda()\n",
        "ckpt = torch.load('./mapper/checkpoints/final/best_model.pt')\n",
        "alpha = float(ckpt['alpha']) * 1.2\n",
        "mapper.load_state_dict(ckpt['state_dict'], strict=True)\n",
        "kwargs = {'latent_space_type': latent_space_type}\n",
        "parsingNet = get_parsingNet(save_pth='./ckpts/face_parsing.pth')\n",
        "inverter = InverterRemoveHair(\n",
        "        model_name,\n",
        "        Generator=model,\n",
        "        learning_rate=0.01,\n",
        "        reconstruction_loss_weight=1.0,\n",
        "        perceptual_loss_weight=5e-5,\n",
        "        truncation_psi=1.0,\n",
        "        logger=None\n",
        ")\n",
        "\n",
        "code_dir = os.path.join(data_dir, 'code')\n",
        "origin_img_dir = os.path.join(data_dir, 'origin')\n",
        "res_dir = os.path.join(data_dir, 'mapper_res')\n",
        "\n",
        "os.makedirs(res_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "fKm4XYmOXygc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_list = glob.glob(os.path.join(code_dir, '*.npy'))\n",
        "\n",
        "total_num = len(code_list)\n",
        "\n",
        "print(f'Editing {total_num} samples.')\n",
        "pbar = tqdm(total=total_num)\n",
        "for index in range(total_num):\n",
        "    pbar.update(1)\n",
        "    code_path = code_list[index]\n",
        "    name = os.path.basename(code_path)[:-4]\n",
        "    f_path_png = os.path.join(origin_img_dir, f'{name}.png')\n",
        "    f_path_jpg = os.path.join(origin_img_dir, f'{name}.jpg')\n",
        "    if os.path.exists(os.path.join(res_dir, f'{name}.png')):\n",
        "        continue\n",
        "    if os.path.exists(f_path_png):\n",
        "        origin_img_path = f_path_png\n",
        "    elif os.path.exists(f_path_jpg):\n",
        "        origin_img_path = f_path_jpg\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    latent_codes_origin = np.reshape(np.load(code_path), (1, 18, 512))\n",
        "\n",
        "    mapper_input = latent_codes_origin.copy()\n",
        "    mapper_input_tensor = torch.from_numpy(mapper_input).cuda().float()\n",
        "    edited_latent_codes = latent_codes_origin\n",
        "    edited_latent_codes[:, :8, :] += alpha * mapper(mapper_input_tensor).to('cpu').detach().numpy()\n",
        "\n",
        "    origin_img = cv2.imread(origin_img_path)\n",
        "\n",
        "    outputs = model.easy_style_mixing(latent_codes=edited_latent_codes,\n",
        "                                      style_range=range(7, 18),\n",
        "                                      style_codes=latent_codes_origin,\n",
        "                                      mix_ratio=0.8,\n",
        "                                      **kwargs\n",
        "                                      )\n",
        "\n",
        "    edited_img = outputs['image'][0][:, :, ::-1]\n",
        "\n",
        "    # --remain_ear: preserve the ears in the original input image.\n",
        "    hair_mask = get_hair_mask(img_path=origin_img, net=parsingNet, include_hat=True, include_ear=True)\n",
        "\n",
        "    mask_dilate = cv2.dilate(hair_mask,\n",
        "                             kernel=np.ones((50, 50), np.uint8))\n",
        "    mask_dilate_blur = cv2.blur(mask_dilate, ksize=(30, 30))\n",
        "    mask_dilate_blur = (hair_mask + (255 - hair_mask) / 255 * mask_dilate_blur).astype(np.uint8)\n",
        "\n",
        "    face_mask = 255 - mask_dilate_blur\n",
        "\n",
        "    index = np.where(face_mask > 0)\n",
        "    cy = (np.min(index[0]) + np.max(index[0])) // 2\n",
        "    cx = (np.min(index[1]) + np.max(index[1])) // 2\n",
        "    center = (cx, cy)\n",
        "\n",
        "    res_save_path = os.path.join(res_dir, f'{name}.png')\n",
        "\n",
        "    mixed_clone = cv2.seamlessClone(origin_img, edited_img, face_mask[:, :, 0], center, cv2.NORMAL_CLONE)\n",
        "\n",
        "\n",
        "    cv2.imwrite(res_save_path, mixed_clone)\n"
      ],
      "metadata": {
        "id": "aUo1IJc-YFcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: visualize results"
      ],
      "metadata": {
        "id": "x60yTlVyYHnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "8GZPqpsMYMmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for res_path in glob.glob('./test_data/mapper_res/*'):\n",
        "    res_img = cv2.imread(res_path)[:,:,::-1]\n",
        "    input_path = res_path.replace('mapper_res','origin')\n",
        "    input_img = cv2.imread(input_path)[:,:,::-1]\n",
        "    visualize = np.concatenate([res_img,input_img], axis=1)\n",
        "    res_im = Image.fromarray(visualize)\n",
        "    display(res_im)"
      ],
      "metadata": {
        "id": "fNKnXK-QUX2w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HairMapper.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}