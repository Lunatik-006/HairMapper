{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setup"
      ],
      "metadata": {
        "id": "SEvU2up7WH4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "code",
        "id": "6vaK0s48v8_w",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5922ac2-f9b9-4aa9-e872-edeef9c949c0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'HairMapper'...\n",
            "remote: Enumerating objects: 415, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 415 (delta 21), reused 18 (delta 18), pack-reused 373 (from 1)\u001b[K\n",
            "Receiving objects: 100% (415/415), 38.38 MiB | 33.02 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please wait util all models are downloaded...\n"
          ]
        }
      ],
      "source": [
        "#@title Setup\n",
        "!git clone https://github.com/oneThousand1000/HairMapper\n",
        "import os\n",
        "os.chdir('./HairMapper')\n",
        "\n",
        "# ==================== download checkpoint ====================\n",
        "!pip install gdown\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "print('Please wait util all models are downloaded...')\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "def download_from_google_drive(file_id,file_dst):\n",
        "  downloaded = drive.CreateFile({'id':file_id})\n",
        "  downloaded.FetchMetadata(fetch_all=True)\n",
        "  downloaded.GetContentFile(file_dst)\n",
        "\n",
        "checkpoints ={\n",
        "    'StyleGAN2-ada-Generator.pth':\n",
        "    {\n",
        "        'url':'1EsGehuEdY4z4t21o2LgW2dSsyN3rxYLJ',\n",
        "        'dir': './ckpts'\n",
        "    },\n",
        "    'e4e_ffhq_encode.pt':\n",
        "    {\n",
        "        'url':'1cUv_reLE6k3604or78EranS7XzuVMWeO',\n",
        "        'dir': './ckpts'\n",
        "    },\n",
        "    'model_ir_se50.pth':\n",
        "    {\n",
        "        'url':'1GIMopzrt2GE_4PG-_YxmVqTQEiaqu5L6',\n",
        "        'dir': './ckpts'\n",
        "    },\n",
        "    'face_parsing.pth':\n",
        "    {\n",
        "        'url':'1IMsrkXA9NuCEy1ij8c8o6wCrAxkmjNPZ',\n",
        "        'dir': './ckpts'\n",
        "    },\n",
        "    'vgg16.pth':\n",
        "    {\n",
        "        'url':'1EPhkEP_1O7ZVk66aBeKoFqf3xiM4BHH8',\n",
        "        'dir': './ckpts'\n",
        "    }\n",
        "}\n",
        "for ckpt in checkpoints:\n",
        "  name = ckpt\n",
        "  url = checkpoints[name]['url']\n",
        "  output_dir = checkpoints[name]['dir']\n",
        "  os.makedirs(output_dir,exist_ok=True)\n",
        "  output_path = os.path.join(output_dir,name)\n",
        "  #gdown.download(url=url,output=output_path,quiet=False) # bug\n",
        "  download_from_google_drive(file_id=url, file_dst=output_path)\n",
        "\n",
        "classification_ckpt =[\n",
        "        {'url':'1SSw6vd-25OGnLAE0kuA-_VHabxlsdLXL',\n",
        "        'dir': './classifier/gender_classification'},\n",
        "        {'url':'1n14ckDcgiy7eu-e9XZhqQYb5025PjSpV',\n",
        "        'dir': './classifier/hair_classification'}\n",
        "]\n",
        "for clf_ckpt_dict in classification_ckpt:\n",
        "  name = 'classification_model.pth'\n",
        "  url = clf_ckpt_dict['url']\n",
        "  output_dir = clf_ckpt_dict['dir']\n",
        "  os.makedirs(output_dir,exist_ok=True)\n",
        "  output_path = os.path.join(output_dir,name)\n",
        "  #gdown.download(url=url,output=output_path,quiet=False)\n",
        "  download_from_google_drive(file_id=url, file_dst=output_path)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== install packages ====================\n",
        "!pip install torch===2.0.0+cu117 torchvision===0.15.0+cu117 torchaudio===2.0.0+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -r requirements.txt\n",
        "!pip install pillow==9.5.0\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7raPzfYlJs3K",
        "outputId": "ca309892-a5b1-43e8-cf86-780bdc4d71ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===2.0.0+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torch-2.0.0%2Bcu117-cp311-cp311-linux_x86_64.whl (1843.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m919.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision===0.15.0+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.15.0%2Bcu117-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio===2.0.0+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torchaudio-2.0.0%2Bcu117-cp311-cp311-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (4.13.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch===2.0.0+cu117) (3.1.6)\n",
            "Collecting triton==2.0.0 (from torch===2.0.0+cu117)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision===0.15.0+cu117) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision===0.15.0+cu117) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision===0.15.0+cu117) (11.1.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch===2.0.0+cu117) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch===2.0.0+cu117)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch===2.0.0+cu117) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision===0.15.0+cu117) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch===2.0.0+cu117) (1.3.0)\n",
            "Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed lit-18.1.8 torch-2.0.0+cu117 torchaudio-2.0.0+cu117 torchvision-0.15.0+cu117 triton-2.0.0\n",
            "Collecting tqdm==4.60.0 (from -r requirements.txt (line 1))\n",
            "  Downloading tqdm-4.60.0-py2.py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.25.1 (from -r requirements.txt (line 2))\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting matplotlib==3.4.1 (from -r requirements.txt (line 3))\n",
            "  Downloading matplotlib-3.4.1.tar.gz (37.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyYAML==5.4.1 (from -r requirements.txt (line 4))\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting pillow==9.5.0\n",
            "  Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pillow-9.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "c4889ad7f62a482a864c8609d8230f1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-05 12:03:54--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250405T120355Z&X-Amz-Expires=300&X-Amz-Signature=d3df04d83865f80bd6ca389f234accdbfebc99cac167fc468d2e9b30731a17c4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-05 12:03:55--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250405T120355Z&X-Amz-Expires=300&X-Amz-Signature=d3df04d83865f80bd6ca389f234accdbfebc99cac167fc468d2e9b30731a17c4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip’\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-04-05 12:03:55 (4.98 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "  inflating: /usr/local/bin/ninja    \n",
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: pre-trained models access\n",
        "\n",
        "Please fill out this form for **pre-trained models access**: https://forms.gle/a5pRbE3yxEr7sZDm7\n",
        "\n",
        "Then fill out the mapper_url with the url of [Final HairMapper]\n",
        "\n"
      ],
      "metadata": {
        "id": "Vf0wbY4dVOqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapper_url = 'https://drive.google.com/file/d/1F3oujXbvalqEOixcAkIyURuY512nmroe' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "h0glHNtLWQTN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: download pre-trained model and test image"
      ],
      "metadata": {
        "id": "By8BOsUlWlVf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "code",
        "id": "OSnXgjN8z69C"
      },
      "outputs": [],
      "source": [
        "#@title Download Pretrain Models\n",
        "\n",
        "name = 'best_model.pt'\n",
        "mapper_url = mapper_url.replace('https://drive.google.com/file/d/','')\n",
        "output_dir = './mapper/checkpoints/final'\n",
        "os.makedirs(output_dir,exist_ok=True)\n",
        "output_path = os.path.join(output_dir,name)\n",
        "download_from_google_drive(file_id=mapper_url, file_dst=output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1kPIBkM64Vkq"
      },
      "outputs": [],
      "source": [
        "#@title Download test image\n",
        "name = '00010.png'\n",
        "url = '1f-cHWMczIyjYBWRnypi1brOpFf2skgWd'\n",
        "output_dir = './test_data/origin'\n",
        "os.makedirs(output_dir,exist_ok=True)\n",
        "output_path = os.path.join(output_dir,name)\n",
        "download_from_google_drive(file_id=url, file_dst=output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Run encoder"
      ],
      "metadata": {
        "id": "C-kaQzhWWvPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./encoder4editing')"
      ],
      "metadata": {
        "id": "iiZkiA0jUSGH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please put the real images to **./test_data/origin** (examplar data can be found in ./test_data/origin/00006.png).\n",
        "\n"
      ],
      "metadata": {
        "id": "OYXDMXr6VomP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0\"\n",
        "!pip install pillow==9.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olaUqUdKOdbe",
        "outputId": "4803431f-ebce-4223-8d5a-a7b645a79872"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Requirement already satisfied: pillow==9.5.0 in /usr/local/lib/python3.11/dist-packages (9.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7tgDxBy8NyZ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "code",
        "id": "g48Gc41R49C-",
        "outputId": "db1b6661-3460-4d55-f5dd-04a29a8fc14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'is_directory' from 'PIL._util' (/usr/local/lib/python3.11/dist-packages/PIL/_util.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3cca747faf25>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_optical_flow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlyingChairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlyingThings3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHD1K\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKittiFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSintel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from ._stereo_matching import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mCarlaStereo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mCREStereo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mETH3DStereo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/_optical_flow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_read_png_16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_read_pfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m __all__ = [\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_deprecate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_directory' from 'PIL._util' (/usr/local/lib/python3.11/dist-packages/PIL/_util.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from argparse import Namespace\n",
        "import sys\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from PIL import ImageFile\n",
        "import glob\n",
        "import os\n",
        "import argparse\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from models.psp import pSp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_on_batch(inputs, net):\n",
        "    latents = net(inputs.to(\"cuda\").float(), randomize_noise=False, return_latents=True)\n",
        "    return latents\n"
      ],
      "metadata": {
        "id": "oM97v_b7XG4G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_transforms = transforms.Compose([\n",
        "          transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]\n",
        "            )\n",
        "model_path = \"../ckpts/e4e_ffhq_encode.pt\"\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts= Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()"
      ],
      "metadata": {
        "id": "cRgwRCs9XLan",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "959c25de-7d04-4f7a-9616-e57237d64899"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6da0cc26d813>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m img_transforms = transforms.Compose([\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]\n\u001b[1;32m      5\u001b[0m             )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '../test_data'\n",
        "file_dir = os.path.join(data_dir,'origin')\n",
        "code_dir = os.path.join(data_dir,'code')\n",
        "if not os.path.exists(code_dir):\n",
        "    os.mkdir(code_dir)\n",
        "for file_path in glob.glob(os.path.join(file_dir,'*.png'))+glob.glob(os.path.join(file_dir,'*.jpg')):\n",
        "    name = os.path.basename(file_path)[:-4]\n",
        "    code_path =os.path.join(code_dir,f'{name}.npy')\n",
        "    if os.path.exists(code_path):\n",
        "        continue\n",
        "    input_image = PIL.Image.open(file_path).convert('RGB')\n",
        "    transformed_image = img_transforms(input_image)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        latents = run_on_batch(transformed_image.unsqueeze(0), net)\n",
        "        latent = latents[0].cpu().numpy()\n",
        "        latent = np.reshape(latent,(1,18,512))\n",
        "        np.save(code_path,latent)\n",
        "        print(f'save to {code_path}')\n"
      ],
      "metadata": {
        "id": "kEKEdnVUXc7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Run HairMaper"
      ],
      "metadata": {
        "id": "e1RcV6nhWz9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('../')"
      ],
      "metadata": {
        "id": "t_N3sGzZUT-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import argparse\n",
        "import cv2\n",
        "from styleGAN2_ada_model.stylegan2_ada_generator import StyleGAN2adaGenerator\n",
        "from tqdm import tqdm\n",
        "from classifier.src.feature_extractor.hair_mask_extractor import get_hair_mask, get_parsingNet\n",
        "from mapper.networks.level_mapper import LevelMapper\n",
        "import torch\n",
        "import glob\n",
        "from diffuse.inverter_remove_hair import InverterRemoveHair\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "import os\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {
        "id": "XPrzEeq8WmfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'stylegan2_ada'\n",
        "latent_space_type = 'wp'\n",
        "data_dir = './test_data'\n",
        "print(f'Initializing generator.')\n",
        "model = StyleGAN2adaGenerator(model_name, logger=None, truncation_psi=1.0)\n",
        "\n",
        "mapper = LevelMapper(input_dim=512).eval().cuda()\n",
        "ckpt = torch.load('./mapper/checkpoints/final/best_model.pt')\n",
        "alpha = float(ckpt['alpha']) * 1.2\n",
        "mapper.load_state_dict(ckpt['state_dict'], strict=True)\n",
        "kwargs = {'latent_space_type': latent_space_type}\n",
        "parsingNet = get_parsingNet(save_pth='./ckpts/face_parsing.pth')\n",
        "inverter = InverterRemoveHair(\n",
        "        model_name,\n",
        "        Generator=model,\n",
        "        learning_rate=0.01,\n",
        "        reconstruction_loss_weight=1.0,\n",
        "        perceptual_loss_weight=5e-5,\n",
        "        truncation_psi=1.0,\n",
        "        logger=None\n",
        ")\n",
        "\n",
        "code_dir = os.path.join(data_dir, 'code')\n",
        "origin_img_dir = os.path.join(data_dir, 'origin')\n",
        "res_dir = os.path.join(data_dir, 'mapper_res')\n",
        "\n",
        "os.makedirs(res_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "fKm4XYmOXygc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_list = glob.glob(os.path.join(code_dir, '*.npy'))\n",
        "\n",
        "total_num = len(code_list)\n",
        "\n",
        "print(f'Editing {total_num} samples.')\n",
        "pbar = tqdm(total=total_num)\n",
        "for index in range(total_num):\n",
        "    pbar.update(1)\n",
        "    code_path = code_list[index]\n",
        "    name = os.path.basename(code_path)[:-4]\n",
        "    f_path_png = os.path.join(origin_img_dir, f'{name}.png')\n",
        "    f_path_jpg = os.path.join(origin_img_dir, f'{name}.jpg')\n",
        "    if os.path.exists(os.path.join(res_dir, f'{name}.png')):\n",
        "        continue\n",
        "    if os.path.exists(f_path_png):\n",
        "        origin_img_path = f_path_png\n",
        "    elif os.path.exists(f_path_jpg):\n",
        "        origin_img_path = f_path_jpg\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    latent_codes_origin = np.reshape(np.load(code_path), (1, 18, 512))\n",
        "\n",
        "    mapper_input = latent_codes_origin.copy()\n",
        "    mapper_input_tensor = torch.from_numpy(mapper_input).cuda().float()\n",
        "    edited_latent_codes = latent_codes_origin\n",
        "    edited_latent_codes[:, :8, :] += alpha * mapper(mapper_input_tensor).to('cpu').detach().numpy()\n",
        "\n",
        "    origin_img = cv2.imread(origin_img_path)\n",
        "\n",
        "    outputs = model.easy_style_mixing(latent_codes=edited_latent_codes,\n",
        "                                      style_range=range(7, 18),\n",
        "                                      style_codes=latent_codes_origin,\n",
        "                                      mix_ratio=0.8,\n",
        "                                      **kwargs\n",
        "                                      )\n",
        "\n",
        "    edited_img = outputs['image'][0][:, :, ::-1]\n",
        "    #edited_img = cv2.resize(edited_img, (origin_img.shape[1], origin_img.shape[0]))\n",
        "\n",
        "    # --remain_ear: preserve the ears in the original input image.\n",
        "    hair_mask = get_hair_mask(img_path=origin_img, net=parsingNet, include_hat=True, include_ear=True)\n",
        "\n",
        "    mask_dilate = cv2.dilate(hair_mask,\n",
        "                             kernel=np.ones((50, 50), np.uint8))\n",
        "    mask_dilate_blur = cv2.blur(mask_dilate, ksize=(30, 30))\n",
        "    mask_dilate_blur = (hair_mask + (255 - hair_mask) / 255 * mask_dilate_blur).astype(np.uint8)\n",
        "\n",
        "    face_mask = 255 - mask_dilate_blur\n",
        "    face_mask = cv2.resize(face_mask, (origin_img.shape[1], origin_img.shape[0]))\n",
        "    #if len(face_mask.shape) == 2:\n",
        "    #    face_mask = cv2.cvtColor(face_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    index = np.where(face_mask > 0)\n",
        "    cy = (np.min(index[0]) + np.max(index[0])) // 2\n",
        "    cx = (np.min(index[1]) + np.max(index[1])) // 2\n",
        "    center = (cx, cy)\n",
        "\n",
        "    res_save_path = os.path.join(res_dir, f'{name}.png')\n",
        "\n",
        "    mixed_clone = cv2.seamlessClone(origin_img, edited_img, face_mask[:, :, 0], center, cv2.NORMAL_CLONE)\n",
        "\n",
        "\n",
        "    cv2.imwrite(res_save_path, mixed_clone)\n"
      ],
      "metadata": {
        "id": "aUo1IJc-YFcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: visualize results"
      ],
      "metadata": {
        "id": "x60yTlVyYHnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "8GZPqpsMYMmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for res_path in glob.glob('./test_data/mapper_res/*'):\n",
        "    res_img = cv2.imread(res_path)[:,:,::-1]\n",
        "    #res_img = cv2.resize(res_img, (512,512))\n",
        "    input_path = res_path.replace('mapper_res','origin')\n",
        "    input_img = cv2.imread(input_path)[:,:,::-1]\n",
        "    #input_img = cv2.resize(input_img, (1024, 1024))\n",
        "    #visualize = np.concatenate([res_img,input_img], axis=1)\n",
        "    res_im = Image.fromarray(res_img)\n",
        "    input_im= Image.fromarray(input_img)\n",
        "    display(res_im)\n",
        "    display(input_im)"
      ],
      "metadata": {
        "id": "fNKnXK-QUX2w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HairMapper.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}